{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)  \n",
    "**a)** какая задача будет решаться (классификация/регрессия/кластеризация/еще что-то)\n",
    "\n",
    "Здесь в принципе можно решать любую задачу в зависимости от данных, которые были найдены. Я нашла данные, состоящие из текста отзыва и оценки от 1 до 5. Поэтому в данном случае можно решать, например, задачу регрессии, что в принципе имеет смысл так как на метках есть порядок (5 > 1 и не обязательно считать эти метки категориальными). Также можно решать задачу класссификации на 5 классов. Я решала задачу классификации только на 2 класса, преобразовав исходные 5 меток в 0 или 1, так как в задании требовалось именно определение тональности вида positive / negative.\n",
    "\n",
    "**b)** какими будут целевые значения (например, классы в задаче классификации) - почему именно такими, как прогнозы будут показываться в демонстрации (например: каким-то числом, текстом, цветом)\n",
    "\n",
    "Как я сказала в предыдущем пункте я рассматриваю в качестве целевых значений 0 или 1 : негативный или позитивный отзыв соответственно. Выбрала именно такие метки так как во-первых, заданием было научиться отличать позитивные отзывы от негативных и во-вторых, эта задача чуть проще, чем классфикация на 5 классов и простым методам будет проще с ней справиться. В демонстрации я просто буду говорить какого вида данный отзыв : positive или negative.\n",
    "\n",
    "**c)** как измерять качество, чтобы было более-менее интуитивно понятно, высокое оно или не очень\n",
    "\n",
    "В силу того, что решается задача классификации на 2 класса, то у нас есть море метрик, которые мы можем рассматривать : accuracy, precision, recall, F1. Однако можно заметить, что классы у нас очень несбалансированы, негативных отзывов в разы больше. Поэтому accuracy лучше не брать. Лучше посчитать F1-меру.\n",
    "\n",
    "**d)** на каких отзывах должна работать демонстрация (язык, длина, наличие ошибок и сленга в тексте).\n",
    "\n",
    "Я парсила сайт отзывов на русские банки с отзывами на русском. Поэтому язык - русский. Длина должна быть не очень большой, так как я рассматривала не полный текст отзыва (далее объяснено почему), а лишь первые 3-6 предложений. К ошибкам модель скорее неустойчива так в качестве признакового описания отзыва используется bag of words. И хоть я и произвожу лемматизацию слов, одно и то же слово с ошибкой и без скорее всего распознается как разные слова. Чтобы избежать этого можно было бы использовать мешок из  n-gramm и тогда модель была бы менее чувствительна к ошибкам. К небольшому сленгу модель должна быть устойчива так как выборка содержит некоторые примеры со сленгом, хотя их скорее всего не очень много.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "small_responses = []\n",
    "marks = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Парсим страницы с отзывами с сайта banki.ru. На странице www.banki.ru/services/responses/list содержится много отзывов(по 25 на страницу). К почти каждому отзыву человек прилагает оценку от 1 до 5.\n",
    "\n",
    "Однако эти отзывы ограничены в кол-ве символов и чтобы прочитать каждый отзыв полностью нужно переходить на другую страницу. Я не стала парсить каждый отзыв полностью так как для того, чтобы не забанили на данном сайте нужно ждать около 10-15 секунд между запросами и тогда парсинг полных отзывов занял бы чуть больше суток. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in np.arange(140, 380):\n",
    "    fp = urllib.request.urlopen(\"http://www.banki.ru/services/responses/list/?page=\" + str(page))\n",
    "    html = fp.read()\n",
    "    html_doc = html.decode(\"utf8\")\n",
    "    fp.close()\n",
    "\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "    articles = soup.find_all('article')\n",
    "    for article in articles:\n",
    "\n",
    "        if 'Без оценки' in article.find_all('div')[1].get_text().strip():\n",
    "            continue\n",
    "\n",
    "        mark = re.findall(r\"\\d\", article.find_all('div')[1].get_text())[0]\n",
    "   \n",
    "        title = article.find_all('div')[0].get_text().strip()\n",
    "        small_response = article.find_all('div')[3].get_text()\n",
    "        small_response = small_response.replace('Весь отзыв', '').strip()\n",
    "\n",
    "        small_responses.append(title + ' ' + small_response)\n",
    "        marks.append(mark)\n",
    "\n",
    "    rand_sec = np.random.randint(7, 15)\n",
    "    time.sleep(rand_sec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6972"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(small_responses) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на соотношение классов. Видим, что больше всего недовольных. Также видим, что в нашей выборке мало 3 и 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4, 5]), array([3860,  691,  279,  214, 1928]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marks = np.array(marks).astype(int)\n",
    "np.unique(marks, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша задача состоит не в предсказывании шкалы от 1 до 5, нам лишь нужно сказать плохой отзыв или нет. Поэтому объединим 1 и 2 в плохой отзыв, а 4 и 5 в хороший. С тройкой не понятно, что делать - кажется, что она бывает и плохим, и хорошим отзывом. Лучше не будем ее трогать, их все равно не много. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeces_considered = np.where(marks!=3)[0]\n",
    "\n",
    "new_marks = marks[indeces_considered]\n",
    "\n",
    "new_marks[new_marks==1] = 0\n",
    "new_marks[new_marks==2] = 0\n",
    "new_marks[new_marks==5] = 1\n",
    "new_marks[new_marks==4] = 1\n",
    "\n",
    "\n",
    "small_responses = np.array(small_responses)\n",
    "new_responses = small_responses[indeces_considered]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from joblib import load, dump\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем данные на test и train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_responses, test_responses, train_marks, test_marks = train_test_split(new_responses, new_marks, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем лемматизацию. Здесь можно было бы еще и стоп-слова убрать, но без них работает чуть похуже - наверно из-за небольшого размера выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "for i, response in enumerate(train_responses):\n",
    "    train_responses[i] = ' '.join([morph.parse(word)[0].normal_form for word in response.split()])\n",
    "    \n",
    "for i, response in enumerate(test_responses):\n",
    "    test_responses[i] = ' '.join([morph.parse(word)[0].normal_form for word in response.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве признакового описания берем bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "train_bag_words = vectorizer.fit_transform(train_responses)\n",
    "test_bag_words = vectorizer.transform(test_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем обучать SVM с линейным ядром."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC()\n",
    "clf.fit(train_bag_words, train_marks)\n",
    "predictions = clf.predict(test_bag_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим на разные метрики. Видим, что в принципе для простой модели, небольшого размера выборки и текстовых данных получилось довольно неплохо. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8492537313432836 0.7455919395465994 0.7551020408163265 0.736318407960199\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "print(accuracy_score(predictions, test_marks),\n",
    "      f1_score(predictions, test_marks), \n",
    "      precision_score(predictions, test_marks), \n",
    "      recall_score(predictions, test_marks) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как будет работать логистическая регрессия. Видим, что мы получили результат сравнивнимо лучше по F1. Также recall и accuracy сильно выросли."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8776119402985074 0.7807486631016043 0.7498979591836735 0.8202247191011236\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(train_bag_words, train_marks)\n",
    "predictions = clf.predict(test_bag_words)\n",
    "print(accuracy_score(predictions, test_marks),\n",
    "      f1_score(predictions, test_marks), \n",
    "      precision_score(predictions, test_marks), \n",
    "      recall_score(predictions, test_marks) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем модель и vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_dump_log.pkl', 'wb') as output_file:\n",
    "    pickle.dump(clf, output_file)\n",
    "    \n",
    "with open('vectorizer_dump.pkl', 'wb') as output_file:\n",
    "    pickle.dump(vectorizer, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
